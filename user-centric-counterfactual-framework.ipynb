{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\"\n",
    "        )\n",
    "logger = logging.getLogger(\"CFE-Pipeline\")"
   ],
   "id": "602299325acbae4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# MODULE ONE - DATA CONTEXT MANAGER",
   "id": "1d0eeaa300a5940c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ],
   "id": "b26729857245d808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# german data\n",
    "column_names = ['age', 'sex', 'job', 'housing', 'saving account', 'checking account',\n",
    "                'credit amount', 'duration', 'purpose', 'risk']\n",
    "\n",
    "german_data = pd.read_csv('german_credit_data.csv', header = None, names= column_names, na_values='?', skipinitialspace=True)\n",
    "german_data.dropna(inplace=True)\n",
    "print(\"Data has been cleaned. All rows with '?' have been removed.\")\n",
    "len(german_data)"
   ],
   "id": "5cd2ba678b7891c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "german_data.head(10)",
   "id": "bb1648bfe51fb9a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataset preprocessing\n",
    "\n",
    "# dataset and target variable\n",
    "g_data = german_data.drop(columns=['risk'], axis=1)\n",
    "target = german_data['risk'].apply(lambda x: 1 if x == 'good' else 0)\n",
    "\n",
    "# duplicate dataframe\n",
    "gd_data = g_data.copy()\n",
    "\n",
    "# encode categorical features\n",
    "num_cols = ['age', 'job', 'credit amount', 'duration']\n",
    "# to keep the order\n",
    "ordinal_cols = ['saving account', 'checking account']\n",
    "l_encoder_cols = ['sex', 'housing', 'purpose']\n",
    "\n",
    " #  label encoder\n",
    "label_encoders = {}\n",
    "\n",
    "for c in l_encoder_cols:\n",
    "    le = LabelEncoder()\n",
    "    gd_data[c] = le.fit_transform(gd_data[c])\n",
    "    label_encoders[c] = le # Store the entire fitted encoder object\n",
    "\n",
    "# ordinal encoder\n",
    "# Performs ordinal encoding on multiple DataFrame columns.\n",
    "def ordinal_encode(data_f, columns, category_orders):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to modify.\n",
    "        columns (list): A list of column names to encode.\n",
    "        category_orders (list of lists): order for each column.\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the ordinal encoded columns.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    data_f_encoded = data_f.copy()\n",
    "\n",
    "    # Check that the number of columns matches the number of order lists\n",
    "    if len(columns) != len(category_orders):\n",
    "        raise ValueError(\"The number of columns must match the number of category order lists.\")\n",
    "\n",
    "    # Iterate over the columns and their corresponding orders\n",
    "    for i, column in enumerate(columns):\n",
    "        order = category_orders[i]\n",
    "        mapping = {category: j for j, category in enumerate(order)}\n",
    "        data_f_encoded[column] = data_f_encoded[column].map(mapping)\n",
    "\n",
    "    return data_f_encoded\n",
    "\n",
    "# ordering based on the amount of money in the bank as stated from the dataset\n",
    "s_account_order = ['little', 'moderate', 'rich', 'quite rich']\n",
    "# ordering based on qty of money\n",
    "c_account_order = ['little', 'moderate', 'rich']\n",
    "\n",
    "order_list = [s_account_order, c_account_order]\n",
    "\n",
    "# data for the model\n",
    "g_features = ordinal_encode(gd_data, ordinal_cols, order_list)\n",
    "\n",
    "# split dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(g_features, target, test_size=0.3, random_state=45)"
   ],
   "id": "f290f66b5f5c694d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# scale numerical data features\n",
    "scaler = StandardScaler().fit(x_train[num_cols])\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train[num_cols])\n",
    "x_test_scaled = scaler.transform(x_test[num_cols])\n",
    "\n",
    "# Combine scaled numerical columns with the already-encoded categorical columns\n",
    "x_train_transformed = np.hstack((x_train_scaled, x_train[ordinal_cols].values, x_train[l_encoder_cols].values))\n",
    "x_test_transformed = np.hstack((x_test_scaled, x_test[ordinal_cols].values, x_test[l_encoder_cols].values))"
   ],
   "id": "4eae7a5edcbe4dda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# decode the encoded values\n",
    "def manual_inverse_transform(transformed_data, scaler, label_encs,\n",
    "                             ord_cols, ord_orders, num_cols, l_enc_cols):\n",
    "\n",
    "    # Preserve index to avoid row-splitting\n",
    "    idx = transformed_data.index\n",
    "\n",
    "    num_col_count = len(num_cols)\n",
    "    ord_col_count = len(ord_cols)\n",
    "\n",
    "    data_num_scaled = transformed_data.iloc[:, :num_col_count]\n",
    "    data_ord_encoded = transformed_data.iloc[:, num_col_count : num_col_count + ord_col_count]\n",
    "    data_nom_encoded = transformed_data.iloc[:, num_col_count + ord_col_count :]\n",
    "\n",
    "    # Inverse numerical features\n",
    "    inv_num = scaler.inverse_transform(data_num_scaled)\n",
    "    df_num = pd.DataFrame(inv_num, columns=num_cols, index=idx)\n",
    "\n",
    "    # Inverse ordinal features\n",
    "    df_ord = pd.DataFrame(data_ord_encoded, columns=ord_cols, index=idx)\n",
    "    for i, col in enumerate(ord_cols):\n",
    "        inv_map = {j: category for j, category in enumerate(ord_orders[i])}\n",
    "        df_ord[col] = (\n",
    "            df_ord[col]\n",
    "            .round()\n",
    "            .astype(int)\n",
    "            .map(inv_map)\n",
    "        )\n",
    "\n",
    "    # Inverse nominal (label-encoded) features\n",
    "    df_nom = pd.DataFrame(index=idx)\n",
    "    for col in l_enc_cols:\n",
    "        raw_vals = data_nom_encoded[col].round().astype(int)\n",
    "\n",
    "        classes = label_encs[col].classes_\n",
    "        clipped_vals = raw_vals.clip(0, len(classes) - 1)\n",
    "\n",
    "        df_nom[col] = label_encs[col].inverse_transform(clipped_vals)\n",
    "\n",
    "    # Concatenate safely (same index everywhere)\n",
    "    full_df = pd.concat([df_num, df_ord, df_nom], axis=1)\n",
    "\n",
    "    # Reorder columns to original layout\n",
    "    return full_df[g_data.columns]\n"
   ],
   "id": "443d69ca1d45485f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# COMBINATION OF SMOTE AND CLASS WEIGHTS TRAINING\n",
    "# SMOTE balances the training data by generating synthetic samples of the minority class; Class weights reinforce the importance of correctly classifying the examples..\n",
    "# Tackles imbalance both at the data level and within the model's learning process, to lead to better model performance."
   ],
   "id": "125b1e4115cb7f21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# classification algorithms to train the model for the predicted outcome\n",
    "\n",
    "# ML model A\n",
    "rf_model = RandomForestClassifier(random_state=42).fit(x_train, y_train)\n",
    "# ML model B\n",
    "svm_model = SVC(kernel='rbf', gamma=0.15, C=100, probability=True).fit(x_train, y_train)\n",
    "# ML model C - change to NN?\n",
    "log_r_model = LogisticRegression(max_iter=1000, solver='lbfgs').fit(x_train, y_train)"
   ],
   "id": "875a29f0733d2efa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # predict\n",
    "rf_pred = rf_model.predict(x_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "svm_pred = svm_model.predict(x_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "\n",
    "logr_pred = log_r_model.predict(x_test)\n",
    "logr_accuracy = accuracy_score(y_test, logr_pred)\n",
    "\n",
    "# print scores\n",
    "print(f\" RF model accuracy: {rf_accuracy:.3f}\")\n",
    "print(f\" SVM model accuracy: {svm_accuracy:.3f}\")\n",
    "print(f\" LogR model accuracy: {logr_accuracy:.3f}\")"
   ],
   "id": "e8da178b5788c078",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# feature importance selection\n",
    "# svm model\n",
    "svm_shap_explainer = shap.KernelExplainer(svm_model.predict_proba, x_train)\n",
    "svm_s_values = svm_shap_explainer.shap_values(x_test)\n"
   ],
   "id": "5843fd9d63743a5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # global feature importance -\n",
    "# SHAP\n",
    "# svm model\n",
    "svm_s_values_total = svm_s_values[:, :, 1]\n",
    "svm_feature_importance = pd.DataFrame({\n",
    "        'feature': x_test.columns,\n",
    "        'importance': np.abs(svm_s_values_total).mean(axis=0)\n",
    "        }).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print('SVM: SHAP\\n', svm_feature_importance)\n",
    "\n",
    "# aggregate feature importance\n",
    "svm_shap_values = svm_feature_importance\n"
   ],
   "id": "c91a788429a10d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# causal graph from selected features\n",
    "# uses the FCI and DirectLINGAM method\n",
    "# FCI: constraint-based method that infers causal skeletons from conditional independence tests\n",
    "# DirectLINGAM: functional method that assumes linear non-guassian relationships to infer causal directions\n",
    "# both: FCI handles latent cofounders, and LiNGAM gives directionality; improves reliability of causal edges\n",
    "# output: A directed causal graph that is grounded in both statistical independence and functional modeling, that provides causal validity\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from causallearn.search.ConstraintBased.FCI import fci\n",
    "from causallearn.utils.cit import fisherz\n",
    "from lingam import DirectLiNGAM\n",
    "import pandas as pd\n",
    "\n",
    "# Number of features to select, or None to use all\n",
    "num_features = 10\n",
    "\n",
    "# important features - select top `num_features` from l_values\n",
    "if num_features is not None:\n",
    "    important_features = svm_shap_values.iloc[:, 0].astype(str).tolist()[:num_features]\n",
    "else:\n",
    "    important_features = svm_shap_values.iloc[:, 0].astype(str).tolist()\n",
    "\n",
    "# match features\n",
    "def match_feature(feat, columns):\n",
    "    # Return the first column name containing feat as substring, else None\n",
    "    for col in columns:\n",
    "        if feat in col:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "important_features_mapped = []\n",
    "for feat in important_features:\n",
    "    matched_col = match_feature(feat, german_data.columns)\n",
    "    if matched_col:\n",
    "        important_features_mapped.append(matched_col)\n",
    "    else:\n",
    "        print(f\"Warning: No match found for {feat}\")\n",
    "\n",
    "important_features = important_features_mapped\n",
    "\n",
    "# identified features from the dataset\n",
    "f_data = german_data[important_features]\n",
    "print(\"Selected columns:\", important_features)\n",
    "print(\"f_data shape:\", f_data.shape)\n",
    "\n",
    "# Remove rows with missing values (FCI and Lingam don't handle NaNs well)\n",
    "f_data = f_data.dropna().reset_index(drop=True)\n",
    "\n",
    "# convert to numeric datatype\n",
    "f_data = f_data.apply(lambda col: pd.factorize(col)[0] if col.dtypes == 'object' else col)\n",
    "\n",
    "# Normalize (required for Lingam to perform well)\n",
    "norm_f_data = (f_data - f_data.mean()) / f_data.std()\n",
    "\n",
    "########################################\n",
    "# Step 1: Constraint-Based Search (FCI)\n",
    "########################################\n",
    "data_d = norm_f_data.to_numpy()\n",
    "fci_result = fci(data_d, fisherz, alpha=0.01, verbose=False)\n",
    "fci_graph = fci_result[0]\n",
    "\n",
    "print(\"\\nFCI Skeleton Edges:\")\n",
    "for edge in fci_graph.get_graph_edges():\n",
    "    i = edge.node1\n",
    "    j = edge.node2\n",
    "    print(f\"{i} <-> {j}\")\n",
    "\n",
    "########################################\n",
    "# Step 2: Functional Causal Discovery (DirectLiNGAM)\n",
    "########################################\n",
    "model = DirectLiNGAM()\n",
    "model.fit(data_d)\n",
    "lingam_adj = model.adjacency_matrix_\n",
    "\n",
    "print(\"\\nLiNGAM Causal Edges:\")\n",
    "for i in range(len(lingam_adj)):\n",
    "    for j in range(len(lingam_adj)):\n",
    "        if lingam_adj[i, j] != 0:\n",
    "            print(f\"{f_data.columns[i]} --> {f_data.columns[j]}\")\n",
    "\n",
    "########################################\n",
    "# Step 3: Merge FCI Skeleton with LiNGAM directions\n",
    "########################################\n",
    "combined_graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes\n",
    "combined_graph.add_nodes_from(f_data.columns)\n",
    "# map edge_nodes to a feature name\n",
    "column_map = {f\"X{i}\": col for i, col in enumerate(f_data.columns)}\n",
    "\n",
    "# Add FCI undirected edges first\n",
    "columns = list(f_data.columns)\n",
    "\n",
    "for edge in fci_graph.get_graph_edges():\n",
    "    i_name = edge.node1.get_name()\n",
    "    j_name = edge.node2.get_name()\n",
    "    if i_name in column_map and j_name in column_map:\n",
    "        i = column_map[i_name]\n",
    "        j = column_map[j_name]\n",
    "        combined_graph.add_edge(i, j, causal_source='fci')\n",
    "\n",
    "# Add directions from LiNGAM if they match FCI edges\n",
    "for i in range(len(lingam_adj)):\n",
    "    for j in range(len(lingam_adj)):\n",
    "        if lingam_adj[i, j] != 0:\n",
    "            src, tgt = f_data.columns[i], f_data.columns[j]\n",
    "            if combined_graph.has_edge(src, tgt):\n",
    "                # Already exists: keep as directed\n",
    "                combined_graph[src][tgt]['weight'] = 'lingam'\n",
    "            elif combined_graph.has_edge(tgt, src):\n",
    "                # Reverse direction if undirected in FCI\n",
    "                combined_graph.remove_edge(tgt, src)\n",
    "                combined_graph.add_edge(src, tgt, causal_source='lingam')\n",
    "            else:\n",
    "                combined_graph.add_edge(src, tgt, causal_source='lingam')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "pos = nx.spring_layout(combined_graph, seed=42, weight=None)\n",
    "edge_labels = nx.get_edge_attributes(combined_graph, 'causal_source')\n",
    "\n",
    "# nx.draw(combined_graph, pos, with_labels=True, node_size=2000, node_color='lightblue', font_size=10, arrowsize=20)\n",
    "# nx.draw_networkx_edge_labels(combined_graph, pos, edge_labels=edge_labels)\n",
    "# plt.title(\"Combined Causal Graph (FCI + LiNGAM)\")\n",
    "# plt.show()\n"
   ],
   "id": "b4c9c299407bc996",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# feature extraction - immutable and actionable features\n",
    "def detect_actionable_immutable(df):\n",
    "    immutable_f = {col for col in df.columns if any(word in col.lower() for word in [\"sex\", \"age\",  \"gender\", \"race\", \"marital-status\", 'ethnicity', 'birth', 'native-country', 'education'])}\n",
    "    actionable_f = set(df.columns) - immutable_f - {\"class\"}\n",
    "    return sorted(actionable_f), sorted(immutable_f)\n",
    "\n",
    "actionable_f, immutable_f = detect_actionable_immutable(german_data)\n",
    "\n",
    "# # Reserve 1â€“2 intermediate features for plausibility\n",
    "# These must have parents in the graph\n",
    "plausibility_nodes = ['purpose', 'job']\n",
    "\n",
    "# Remove from actionable/immutable\n",
    "actionable_f = [f for f in actionable_f if f not in plausibility_nodes]\n",
    "immutable_f = [f for f in immutable_f if f not in plausibility_nodes]\n"
   ],
   "id": "1be985491863a97c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SEM to enforce causal validity for the counterfactual generation (validate causal assumption)\n",
    "# DAG: a graph with directed edges and no cycles, represents causal flow\n",
    "# SEM: a set of equations that models each variable as a function of its causal parents\n",
    "\n",
    "# deterministic\n",
    "def estimate_sems(df, graph):\n",
    "    sem = {}\n",
    "    for node in nx.topological_sort(graph):\n",
    "        parents = list(graph.predecessors(node))\n",
    "        if not parents:\n",
    "            sem[node] = ([], 0)\n",
    "        else:\n",
    "            X = df[parents]\n",
    "            y = df[node]\n",
    "            beta = np.linalg.pinv(X.values) @ y.values\n",
    "            sem[node] = (parents, beta)\n",
    "    return sem\n",
    "\n",
    "# probabilistic\n",
    "# captures noise and variability, required to calculate the plausibility of the generated counterfactual\n",
    "def estimate_p_sems(df, graph):\n",
    "    sem = {}\n",
    "    for node in nx.topological_sort(graph):\n",
    "        parents = list(graph.predecessors(node))\n",
    "\n",
    "        if not parents:\n",
    "            mu = df[node].mean()\n",
    "            sigma = df[node].std()\n",
    "            sem[node] = ([], np.array([mu]), sigma)  # store mean as beta-like vector\n",
    "        else:\n",
    "            X = df[parents]\n",
    "            y = df[node]\n",
    "            beta = np.linalg.pinv(X.values) @ y.values\n",
    "            residuals = y - X @ beta\n",
    "            sigma = np.std(residuals)\n",
    "            sem[node] = (parents, beta, sigma)\n",
    "    return sem\n",
    "\n",
    "# extract a DAG with only LiNGAM-directed edges (to ensure acyclicity)\n",
    "DAG_graph = nx.DiGraph(\n",
    "    (u, v, d) for u, v, d in combined_graph.edges(data=True)\n",
    "    if d.get(\"causal_source\") == \"lingam\")\n",
    "\n",
    " #Optional: Check if DAG is valid\n",
    "assert nx.is_directed_acyclic_graph(DAG_graph), \"Graph must be a DAG for SEM estimation\"\n",
    "\n",
    "# calling the SEM - follows linear_regression\n",
    "sem_equations = estimate_p_sems(norm_f_data, DAG_graph)"
   ],
   "id": "e9caf479b32dd72e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SEM - conversion to callable functions, so it can be used for the counterfactual generation\n",
    "# Enables modular, reusable causal modeling to ensure causal dependencies are respected (causal plausibility enforcement)\n",
    "\n",
    "# a deterministic SEM for the causal plausibility - returns a single value\n",
    "def make_linear_sem_function(parents, beta):\n",
    "    def sem_func(X_parent_values):\n",
    "        return X_parent_values @ beta\n",
    "    return sem_func\n",
    "\n",
    "# a probabilistic SEM for the causal plausibility - returns a distribution\n",
    "def make_probabilistic_sem_function(parents, beta, sigma):\n",
    "    def sem_func(X_parent_values):\n",
    "        if not parents:\n",
    "            mu = beta[0] if isinstance(beta, np.ndarray) else beta\n",
    "            return np.full((X_parent_values.shape[0], 1), mu), sigma\n",
    "        else:\n",
    "            mu = X_parent_values @ beta\n",
    "            return mu, sigma\n",
    "    return sem_func\n",
    "\n",
    "default_sigma = 0.5\n",
    "sem_functions = {}\n",
    "\n",
    "for node, values in sem_equations.items():\n",
    "    if len(values) == 3:\n",
    "        # Probabilistic SEM with parents\n",
    "        parents, beta, sigma = values\n",
    "        sem_func = make_probabilistic_sem_function(parents, beta, sigma)\n",
    "        sem_functions[node] = (sem_func, parents)\n",
    "    elif len(values) == 2:\n",
    "        # Root node: values = ([], mu)\n",
    "        _, beta = values\n",
    "        sigma = default_sigma  # assign a default sigma to root node\n",
    "        sem_func = make_probabilistic_sem_function([], beta, sigma)\n",
    "        sem_functions[node] = (sem_func, [])\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected SEM format for node {node}: {values}\")\n",
    "\n",
    "# debugging\n",
    "for node, val in sem_functions.items():\n",
    "    print(node, type(val), len(val))  # should be tuple, len == 2\n"
   ],
   "id": "b053823027590cf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# MODULE TWO: PREFERENCE ELICITATION MODULE",
   "id": "1a9ba71bdfb6eaa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "# class definition\n",
    "@dataclass\n",
    "\n",
    "class DataContext:\n",
    "    def __init__( self, x: np.ndarray, x_df: pd.DataFrame, feature_names: list,\n",
    "                  actionable_features: list, immutable_features: list,\n",
    "                  feature_ranges: dict, causal_graph: dict, model: object,\n",
    "                  num_cols, ord_cols, ord_orders, l_enc_cols):\n",
    "        self.x = x\n",
    "        self.x_df = x_df\n",
    "        self.feature_names = feature_names\n",
    "        self.actionable_features = actionable_features\n",
    "        self.immutable_features = immutable_features\n",
    "        self.feature_ranges = feature_ranges\n",
    "        self.causal_graph = causal_graph\n",
    "        self.model = model\n",
    "        self.num_cols = num_cols\n",
    "        self.ord_cols = ord_cols\n",
    "        self.ord_orders = ord_orders\n",
    "        self.l_enc_cols = l_enc_cols"
   ],
   "id": "e4ed697fa1452674",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# feature ranges definition\n",
    "# using an hybrid approach - the min-max values of the features and incorporating domain knowledge\n",
    "\n",
    "# domain feature ranges changes per dataset and its features\n",
    "DOMAIN_FEATURE_RANGES = {\n",
    "    \"age\": (18, 90),                 # legal working age\n",
    "    \"housing\": (0, 3),        # German dataset encoding\n",
    "    \"saving account\": (0, 3),       # realistic work hours\n",
    "    \"checking account\": (0, 3)     # IRS-like practical bound\n",
    "}\n",
    "\n",
    "# the dataset without the target column\n",
    "X = g_data\n",
    "def build_feature_ranges(X, numerical_features, domain_ranges):\n",
    "    feature_ranges = {}\n",
    "\n",
    "    for f in numerical_features:\n",
    "        if f in domain_ranges:\n",
    "            feature_ranges[f] = domain_ranges[f]\n",
    "        else:\n",
    "            feature_ranges[f] = (\n",
    "                X[f].quantile(0.01),\n",
    "                X[f].quantile(0.99)\n",
    "            )\n",
    "    return feature_ranges\n",
    "\n",
    "feature_ranges = build_feature_ranges(X=X, numerical_features=num_cols, domain_ranges=DOMAIN_FEATURE_RANGES)"
   ],
   "id": "34972c2320612da8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# data prep for the input data context\n",
    "x_test_transformed = np.hstack((x_test_scaled, x_test[ordinal_cols].values, x_test[l_encoder_cols].values))\n",
    "encoded_columns = num_cols + ordinal_cols + l_encoder_cols\n",
    "x_test_encoded = pd.DataFrame(x_test_transformed, columns=encoded_columns)\n",
    "x_test_encoded[\"risk\"] = y_test.values\n",
    "\n",
    "# sanity check\n",
    "print((x_test_encoded['risk'] == 0).sum())\n",
    "\n",
    "# data instance\n",
    "cf_data_instance = x_test_encoded[x_test_encoded['risk'] == 0].iloc[[20]].copy()\n",
    "cf_data_instance_t = cf_data_instance.drop(columns = ['risk']).to_numpy()\n",
    "features_names = g_data.columns.tolist()\n",
    "\n",
    "# actual data instance = raw data for this index\n",
    "data_instance = manual_inverse_transform( transformed_data=cf_data_instance.drop(columns=[\"risk\"]),\n",
    "                                scaler = scaler, label_encs=label_encoders,\n",
    "                                ord_cols=ordinal_cols, ord_orders=order_list,\n",
    "                                num_cols=num_cols, l_enc_cols=l_encoder_cols)\n",
    "\n",
    "context = DataContext(\n",
    "    x=cf_data_instance_t,\n",
    "    x_df=data_instance,\n",
    "    feature_names=features_names,\n",
    "    actionable_features=actionable_f,\n",
    "    immutable_features=immutable_f,\n",
    "    feature_ranges=feature_ranges,\n",
    "    causal_graph=DAG_graph,\n",
    "    model=svm_model,\n",
    "    num_cols=num_cols,\n",
    "    ord_cols=ordinal_cols,\n",
    "    ord_orders=order_list,\n",
    "    l_enc_cols=l_encoder_cols\n",
    ")\n",
    "\n",
    "TARGET = \"risk\"\n",
    "\n",
    "all_features = [f for f in g_data.columns if f != TARGET]\n",
    "actionable_features = [f for f in actionable_f if f != TARGET]\n",
    "immutable_features = [f for f in immutable_f if f != TARGET]\n",
    "\n",
    "# Debugging purpose - confirming the instances are the same in encoded and transformed state.\n",
    "encoded_instance = cf_data_instance_t\n",
    "print(encoded_instance)\n",
    "\n",
    "raw_instance = data_instance\n",
    "raw_instance"
   ],
   "id": "f59ef26d539179b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# USER PROXY\n",
    "# define a preference schema that determines the kind of preferences that exist,\n",
    "# how they are expressed, and how they influence the CFE generation (traceability)\n",
    "\n",
    "u_preference = {\n",
    "    'feature': str,\n",
    "    'importance_rank': int,\n",
    "    'hard': bool,\n",
    "}\n",
    "\n",
    "# prompt constructor for the user (LLM-agent simulated user)\n",
    "def build_preference_prompt(context: DataContext) -> str:\n",
    "    \"\"\"\n",
    "    Constructs a prompt to simulate a user providing feature-level preferences\n",
    "    for counterfactual generation.\n",
    "    \"\"\"\n",
    "    # current instance\n",
    "    instance_desc = context.x_df.to_dict(orient=\"records\")[0]\n",
    "    # features that can be modified\n",
    "    actionable = \", \".join(context.actionable_features)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a user seeking to improve your desired outcome in a decision system.\n",
    "\n",
    "    Your current profile:\n",
    "    {instance_desc}\n",
    "\n",
    "    You are ONLY allowed to change the following features:\n",
    "    {actionable}\n",
    "\n",
    "    Instructions:\n",
    "    - Select **at least 3 and at most 5** features you would prefer to change\n",
    "    - You do NOT need to select exactly 5 features\n",
    "    - Do NOT include immutable features\n",
    "    - For each selected feature, specify:\n",
    "      - importance_rank: 1 = most important, higher numbers = less important\n",
    "      - whether it is a hard constraint\n",
    "      - a short rationale why you want it changed\n",
    "\n",
    "    Return your response as JSON with this format:\n",
    "    [\n",
    "      {{\n",
    "        \"feature\": \"...\",\n",
    "        \"importance_rank\": 1,\n",
    "        \"hard\": true|false\n",
    "      }}\n",
    "    ]\n",
    "    Before the JSON, briefly explain your reasoning in plain text.\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ],
   "id": "91df942d1ad9eba0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# interface for LLM agents\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class UserPreferenceAgent(ABC):\n",
    "    @abstractmethod\n",
    "    def elicit_preferences(self, context: DataContext) -> list:\n",
    "        pass\n",
    "\n",
    "# OpenAI / GPT-Based Agent\n",
    "# current model: GPT-4.1-mini\n",
    "import logging\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json(llm_output: str):\n",
    "    \"\"\"\n",
    "    Extracts the first JSON array or object from an LLM response.\n",
    "    Assumes reasoning text may precede the JSON.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(\\[.*\\]|\\{.*\\})\", llm_output, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"No JSON found in LLM output\")\n",
    "\n",
    "    return json.loads(match.group())\n",
    "\n",
    "# # WORKS! Doesn't show the simulated user reasoning or thought process\n",
    "# temperature = 0.3 (mostly consistent); 0.5-0.7: has more randomness /high creativity;  0.0 - 0.2: very deterministic/factual/repitive\n",
    "class GPTUserPreferenceAgent(UserPreferenceAgent):\n",
    "    def __init__(self, model=\"gpt-4.1-mini\", temperature=0.5):\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.logger = logging.getLogger(\"CFE.PreferenceAgent\")\n",
    "\n",
    "    def elicit_preferences(self, context: DataContext) -> list:\n",
    "        self.logger.info(\"Preference elicitation started\")\n",
    "\n",
    "        prompt = build_preference_prompt(context)\n",
    "        self.logger.info(\"Prompt constructed for LLM\")\n",
    "        self.logger.debug(\"PROMPT:\\n%s\", prompt)\n",
    "\n",
    "        self.logger.info(\"Invoking LLM model=%s\", self.model)\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "\n",
    "        self.logger.info(\"LLM response received\")\n",
    "\n",
    "        raw_output = response.choices[0].message.content\n",
    "        self.logger.debug(\"RAW LLM OUTPUT:\\n%s\", raw_output)\n",
    "\n",
    "        try:\n",
    "            preferences = json.loads(raw_output)\n",
    "        except json.JSONDecodeError:\n",
    "            self.logger.error(\"Invalid JSON returned by LLM\")\n",
    "            raise ValueError(\"LLM did not return valid JSON\")\n",
    "\n",
    "        self.logger.info(\"Preference parsing successful\")\n",
    "        return preferences"
   ],
   "id": "daeb0778e3280151",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# simulating multiple user personas\n",
    "# WHY: Real users are inconsistent, may not fully understand features semtnatics, and priorites change over time. Additionally, it provides robustness through preference diversity as it can enable the pipeline to detect preference instability, identify domninant features, and discard CFEs that suit a narrow preference profile.\n",
    "\n",
    "SIMULATED_USER_PERSONAS = [\n",
    "    {\n",
    "        \"name\": \"Effort-Minimizing User\",\n",
    "        \"system_prompt\": (\n",
    "            \"You prefer changes that require minimal effort, \"\n",
    "            \"avoid education or occupation changes, \"\n",
    "            \"and favor small numeric adjustments.\"\n",
    "        ),\n",
    "        \"temperature\": 0.9\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Income-Maximizing User\",\n",
    "        \"system_prompt\": (\n",
    "            \"You prioritize changes that most strongly improve income, \"\n",
    "            \"even if they require substantial effort.\"\n",
    "        ),\n",
    "        \"temperature\": 0.7\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Stability-Oriented User\",\n",
    "        \"system_prompt\": (\n",
    "            \"You prefer changes that preserve demographic and employment stability.\"\n",
    "        ),\n",
    "        \"temperature\": 0.5\n",
    "    }\n",
    "]\n",
    "\n",
    "# preference stochasticity - introduce controlled randomness into each simulated user's elicitation process. It captures ambiguity in user articulation, tradeoff between competing priorities and sensitivity to prompt phrasing. Promotes robust CFE generation as it enables expected utility and worst case analysis\n",
    "def inject_preference_stochasticity(preferences, drop_prob=0.2):\n",
    "    \"\"\"\n",
    "    Randomly drops preferences to simulate uncertainty.\n",
    "    \"\"\"\n",
    "    noisy_prefs = []\n",
    "    for p in preferences:\n",
    "        if random.random() > drop_prob:\n",
    "            noisy_prefs.append(p)\n",
    "    return noisy_prefs\n",
    "\n",
    "\n",
    "import random\n",
    "class MultiUserPreferenceAgent:\n",
    "    def __init__(self, model=\"gpt-4.1-mini\", verbose=True):\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "        self.verbose = verbose\n",
    "        self.logger = logging.getLogger(\"CFE.PreferenceAgent\")\n",
    "\n",
    "    def elicit_preferences(self, context, num_users=3):\n",
    "        self.logger.info(\"Starting multi-user preference elicitation\")\n",
    "\n",
    "        sampled_personas = random.sample(\n",
    "            SIMULATED_USER_PERSONAS,\n",
    "            min(num_users, len(SIMULATED_USER_PERSONAS))\n",
    "        )\n",
    "\n",
    "        all_preferences = []\n",
    "\n",
    "        for persona in sampled_personas:\n",
    "            prefs = self._elicit_single_user(context, persona)\n",
    "            all_preferences.append({\n",
    "                \"persona\": persona[\"name\"],\n",
    "                \"preferences\": prefs\n",
    "            })\n",
    "\n",
    "        return all_preferences\n",
    "\n",
    "    def _elicit_single_user(self, context, persona):\n",
    "        prompt = build_preference_prompt(context)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"\\nðŸ§  Simulated User: {persona['name']}\")\n",
    "            print(\"--------------------------------------------------\")\n",
    "            print(prompt)\n",
    "            print(\"--------------------------------------------------\")\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": persona[\"system_prompt\"]},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=persona[\"temperature\"]\n",
    "        )\n",
    "        raw_output = response.choices[0].message.content\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"\\nðŸ§  Raw Response\")\n",
    "            print(\"--------------------------------------------------\")\n",
    "            print(raw_output)\n",
    "            print(\"--------------------------------------------------\")\n",
    "\n",
    "        preferences = extract_json(raw_output)\n",
    "        preferences = inject_preference_stochasticity(preferences, drop_prob=0.0)\n",
    "\n",
    "        return preferences"
   ],
   "id": "683d53d3ef1d632c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# threshold represents consensus constraints, a minimum level of consensus among simulated users required for a feature to be accepted as a global preference constraints\n",
    "\n",
    "from collections import Counter\n",
    "def aggregate_preferences(multi_user_prefs, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Keeps features preferred by at least `threshold` fraction of users.\n",
    "\n",
    "    Accepts:\n",
    "    - Single user dict\n",
    "    - List of user dicts\n",
    "    - Dicts with 'preferences' or 'features'\n",
    "    - Flat list of preference dicts (single user)\n",
    "    \"\"\"\n",
    "    if not multi_user_prefs:\n",
    "        return []\n",
    "\n",
    "    # ---- Normalize to list of users ----\n",
    "    if isinstance(multi_user_prefs, dict):\n",
    "        users = [multi_user_prefs]\n",
    "    elif isinstance(multi_user_prefs, list):\n",
    "        users = multi_user_prefs\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            f\"Expected dict or list, got {type(multi_user_prefs)}\"\n",
    "        )\n",
    "\n",
    "    feature_votes = Counter()\n",
    "    valid_users = 0\n",
    "\n",
    "    for user in users:\n",
    "        # ---- Normalize user preferences ----\n",
    "        if isinstance(user, dict):\n",
    "            prefs = (\n",
    "                user.get(\"preferences\")\n",
    "                or user.get(\"features\")\n",
    "            )\n",
    "        elif isinstance(user, list):\n",
    "            # already a flat list of prefs\n",
    "            prefs = user\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if not prefs:\n",
    "            continue\n",
    "\n",
    "        valid_users += 1\n",
    "\n",
    "        for p in prefs:\n",
    "            if isinstance(p, dict) and \"feature\" in p:\n",
    "                feature_votes[p[\"feature\"]] += 1\n",
    "\n",
    "    if valid_users == 0:\n",
    "        return []\n",
    "\n",
    "    # ---- Aggregate by threshold ----\n",
    "    return [\n",
    "        feature\n",
    "        for feature, count in feature_votes.items()\n",
    "        if count / valid_users >= threshold\n",
    "    ]\n",
    "\n",
    "# for single user\n",
    "def normalize_user_preferences(user_prefs):\n",
    "    \"\"\"\n",
    "    Converts single-user preferences into the format expected by `aggregate_preferences`.\n",
    "    Output format:\n",
    "    {\"preferences\": [{\"feature\": FEATURE_NAME}, ...]}\n",
    "    \"\"\"\n",
    "    if isinstance(user_prefs, dict):\n",
    "        # Already a dict; make sure inner list has 'feature'\n",
    "        prefs = user_prefs.get(\"preferences\") or user_prefs.get(\"features\") or []\n",
    "        normalized = []\n",
    "        for p in prefs:\n",
    "            if isinstance(p, dict):\n",
    "                if \"feature\" in p:\n",
    "                    normalized.append(p)\n",
    "                else:\n",
    "                    # assume key is the feature name\n",
    "                    feature_name = list(p.keys())[0]\n",
    "                    normalized.append({\"feature\": feature_name})\n",
    "        return {\"preferences\": normalized}\n",
    "\n",
    "    elif isinstance(user_prefs, list):\n",
    "        # list of dicts\n",
    "        normalized = []\n",
    "        for p in user_prefs:\n",
    "            if isinstance(p, dict):\n",
    "                if \"feature\" in p:\n",
    "                    normalized.append(p)\n",
    "                else:\n",
    "                    feature_name = list(p.keys())[0]\n",
    "                    normalized.append({\"feature\": feature_name})\n",
    "        return {\"preferences\": normalized}\n",
    "\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported preference type: {type(user_prefs)}\")"
   ],
   "id": "6718a474d8173636",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Validate user preference adheres to the defined preference\n",
    "# single user\n",
    "def validate_single_user_preferences(preferences, context):\n",
    "    \"\"\"\n",
    "    Validates a single user's preference list.\n",
    "    \"\"\"\n",
    "    valid = []\n",
    "\n",
    "    for p in preferences:\n",
    "        feature = p[\"feature\"]\n",
    "\n",
    "        if feature not in context.actionable_features:\n",
    "            continue\n",
    "        if feature in context.immutable_features:\n",
    "            continue\n",
    "\n",
    "        valid.append(p)\n",
    "\n",
    "    return valid\n",
    "\n",
    "# multiple user\n",
    "def validate_multi_user_preferences(multi_user_prefs, context):\n",
    "    \"\"\"\n",
    "    Validates preferences for each simulated user independently.\n",
    "    \"\"\"\n",
    "    validated = []\n",
    "\n",
    "    for user_block in multi_user_prefs:\n",
    "        persona = user_block[\"persona\"]\n",
    "        prefs = user_block[\"preferences\"]\n",
    "\n",
    "        valid_prefs = validate_single_user_preferences(prefs, context)\n",
    "\n",
    "        validated.append({\n",
    "            \"persona\": persona,\n",
    "            \"preferences\": valid_prefs\n",
    "        })\n",
    "\n",
    "    return validated"
   ],
   "id": "141d775f60aec98c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "agent = MultiUserPreferenceAgent(verbose=True)\n",
    "logger.info(\"Requesting user preferences from LLM agent\")\n",
    "\n",
    "# SINGLE USER\n",
    "raw_prefs = agent._elicit_single_user(context, SIMULATED_USER_PERSONAS[1])\n",
    "logger.info(\"User preferences received\")\n",
    "user_preferences = validate_single_user_preferences(raw_prefs, context)\n",
    "\n",
    "# normalize single-user prefs\n",
    "normalized_prefs = normalize_user_preferences(user_preferences)\n",
    "aggregated_features = aggregate_preferences(normalized_prefs, threshold=0.5)\n",
    "\n",
    "# # MULTI USER\n",
    "# raw_prefs = agent.elicit_preferences(context)\n",
    "# logger.info(\"User preferences received\")\n",
    "# user_preferences = validate_multi_user_preferences(raw_prefs, context)\n",
    "# aggregated_features = aggregate_preferences(user_preferences, threshold=0.6)"
   ],
   "id": "bfa865ec3e87d9aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Validated User Preferences:\")\n",
    "for p in user_preferences:\n",
    "    print(p)\n",
    "\n",
    "length_user_preference = len(user_preferences)\n",
    "length_user_preference\n",
    "\n",
    "feasible_features = user_preferences"
   ],
   "id": "a7473573e7ac27cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# MODULE 3: FEATURE UTILITY AND CAUSAL FEASIBILITY FILTER MODULE",
   "id": "d7797cfef11db3ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#  Feature utility and the split of features into tiers\n",
    "\n",
    "# Step 1: Parse user preferences into feature-conditioned utility\n",
    "# lambda weight: 100% represented as 1\n",
    "def build_feature_utility(user_preferences, lambda_weight=1.0):\n",
    "    \"\"\"\n",
    "    Converts LLM user preferences into feature-conditioned utility weights.\n",
    "    \"\"\"\n",
    "    feature_utilities = {}\n",
    "\n",
    "    # Normalize ranks to [0,1] (1 = most important)\n",
    "    ranks = [p['importance_rank'] for p in user_preferences]\n",
    "    max_rank = max(ranks) if ranks else 1\n",
    "\n",
    "    for p in user_preferences:\n",
    "        norm_rank = 1 - ((p['importance_rank'] - 1) / max_rank)  # 1 = most important\n",
    "        alpha = lambda_weight * (1 - norm_rank)  # lower penalty for important features\n",
    "        feature_utilities[p['feature']] = {\n",
    "                                            'alpha': alpha,\n",
    "                                            'hard': p['hard'],\n",
    "                                            'rank': p['importance_rank'],\n",
    "\n",
    "                                        }\n",
    "    return feature_utilities\n",
    "\n",
    "# Step 2: Split features into Tier 1 and Tier 2 candidates, using causal feasibility\n",
    "def split_tiers_with_causal_filter(feature_utilities, context: \"DataContext\"):\n",
    "    \"\"\"\n",
    "    Splits features into Tier 1 (user-preferred) and Tier 2 (causally feasible remaining)\n",
    "    using causal graph checks.\n",
    "    \"\"\"\n",
    "    tier1_candidates = list(feature_utilities.keys())\n",
    "\n",
    "    # Filter Tier 1 features for causal feasibility\n",
    "    tier1_features, rejected_tier1 = filter_causally_feasible_features(tier1_candidates, context)\n",
    "\n",
    "    # Identify causally related features for Tier 2\n",
    "    tier2_candidates = set()\n",
    "    for f in tier1_features:\n",
    "        # Get children of f in causal graph\n",
    "        if f in context.causal_graph.nodes:\n",
    "            children = list(context.causal_graph.successors(f))\n",
    "            tier2_candidates.update(children)\n",
    "\n",
    "    # Exclude Tier 1 features and immutable features\n",
    "    tier2_candidates = [\n",
    "        f for f in tier2_candidates\n",
    "        if f not in tier1_features and f in context.actionable_features\n",
    "    ]\n",
    "\n",
    "    # Filter Tier 2 candidates for causal feasibility\n",
    "    tier2_features, rejected_tier2 = filter_causally_feasible_features(tier2_candidates, context)\n",
    "\n",
    "    return tier1_features, tier2_features, rejected_tier1, rejected_tier2"
   ],
   "id": "8f4996ef8d677cfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# causal feasibility check of user preferences\n",
    "# looking up the causal parents\n",
    "def get_causal_parents(feature, causal_graph):\n",
    "    if feature not in causal_graph.nodes:\n",
    "        return []\n",
    "    return list(causal_graph.predecessors(feature))\n",
    "\n",
    "# checking the causal feasibility for a single feature\n",
    "def is_feature_causally_feasible(feature, context: DataContext, selected_features, hard_only=True):\n",
    "    \"\"\"\n",
    "    Checks if intervening on `feature` is causally feasible\n",
    "    given current selected preference features.\n",
    "    \"\"\"\n",
    "    parents = get_causal_parents(feature, context.causal_graph)\n",
    "\n",
    "    # Immutable parent blocks unless feature is actionable\n",
    "    for p in parents:\n",
    "        if (\n",
    "            p in context.immutable_features\n",
    "            and feature not in context.actionable_features\n",
    "        ):\n",
    "            return False, f\"{feature} has immutable parent {p}\"\n",
    "\n",
    "    # Parent-change requirement unless feature is actionable\n",
    "    for p in parents:\n",
    "        if (\n",
    "            feature not in context.actionable_features\n",
    "            and p not in selected_features\n",
    "            and p not in context.actionable_features\n",
    "        ):\n",
    "            return False, f\"{feature} requires parent {p} to change\"\n",
    "\n",
    "    return True, None\n",
    "\n",
    "# checking the causal feasibility for a set of preferences\n",
    "def filter_causally_feasible_features(aggregated_features, context: DataContext):\n",
    "    \"\"\"\n",
    "    Filters aggregated preference features based on causal feasibility.\n",
    "    \"\"\"\n",
    "    feasible = []\n",
    "    rejected = []\n",
    "\n",
    "    for f in aggregated_features:\n",
    "        ok, reason = is_feature_causally_feasible( feature=f, context=context, selected_features=aggregated_features)\n",
    "        if ok:\n",
    "            feasible.append(f)\n",
    "        else:\n",
    "            rejected.append((f, reason))\n",
    "\n",
    "    return feasible, rejected\n",
    "\n",
    "feasible_features = aggregated_features"
   ],
   "id": "1cac6c2a19b016fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: build feature-conditioned utility\n",
    "feature_utils = build_feature_utility(user_preferences, lambda_weight=1.0)\n",
    "\n",
    "# TIERED FEATURE PARTITIONING\n",
    "# Step 2: split tiers with causal feasibility\n",
    "tier1_features, tier2_features, rejected_t1, rejected_t2 = split_tiers_with_causal_filter(feature_utils, context)\n",
    "\n",
    "print(\"\\nFeature-conditioned utilities:\")\n",
    "for f, v in feature_utils.items():\n",
    "    print(f\"{f}: {v}\")\n",
    "\n",
    "print(\"\\nTier 1 features (user-preferred & causally feasible):\", tier1_features)\n",
    "print(\"Tier 2 features (causally related & feasible):\", tier2_features)\n",
    "print(\"\\nRejected Tier 1 features due to causal constraints:\", rejected_t1)\n",
    "print(\"Rejected Tier 2 features due to causal constraints:\", rejected_t2)"
   ],
   "id": "3287fe8c1e7ea299",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MODULE 4: MULTI-OBJECTIVE OPTIMIZATION MODULE\n",
    "# optimizes the defined objectives to produce CFEs that are both user-aligned and actionable."
   ],
   "id": "c0f39f1ae09f05ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# reconstruct the counterfactuals to the human-readable data\n",
    "def decode_data(valid_cfs: np.ndarray, scaler: StandardScaler,label_encoders: dict,\n",
    "                ord_cols: list, ord_orders: list, num_cols: list, l_enc_cols: list,\n",
    "                feature_names: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reconstruct counterfactuals generated by the CFE pipeline to human-readable values.\n",
    "\n",
    "    Args:\n",
    "        cf_array: np.ndarray of counterfactuals (shape: num_cfs x num_features)\n",
    "        scaler: Fitted StandardScaler for numerical features\n",
    "        label_encoders: dict of fitted LabelEncoders for nominal features\n",
    "        ord_cols: List of ordinal column names\n",
    "        ord_orders: List of lists with the ordering of each ordinal column\n",
    "        num_cols: List of numerical feature names\n",
    "        l_enc_cols: List of nominal categorical feature names\n",
    "        feature_names: List of all feature names in order (num_cols + ord_cols + l_enc_cols)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Counterfactuals in original, human-readable format\n",
    "    \"\"\"\n",
    "    cf_df = pd.DataFrame(valid_cfs, columns=feature_names)\n",
    "\n",
    "    # a. Inverse transform numerical features\n",
    "    df_num = pd.DataFrame(\n",
    "        scaler.inverse_transform(cf_df[num_cols]),\n",
    "        columns=num_cols\n",
    "    )\n",
    "\n",
    "    # b. Inverse transform ordinal features\n",
    "    df_ord = pd.DataFrame(cf_df[ord_cols].round().astype(int), columns=ord_cols)\n",
    "    for i, col in enumerate(ord_cols):\n",
    "        inv_map = {idx: val for idx, val in enumerate(ord_orders[i])}\n",
    "        df_ord[col] = df_ord[col].map(inv_map)\n",
    "\n",
    "    # c. Inverse transform label-encoded nominal features\n",
    "    df_nom = pd.DataFrame(columns=l_enc_cols)\n",
    "    for col in l_enc_cols:\n",
    "        vals = cf_df[col].round().astype(int)\n",
    "        vals = vals.clip(lower=0, upper=len(label_encoders[col].classes_) - 1)\n",
    "        df_nom[col] = label_encoders[col].inverse_transform(vals)\n",
    "\n",
    "    # Combine all features in the original order\n",
    "    reconstructed_cf = pd.concat([df_num, df_ord, df_nom], axis=1)\n",
    "\n",
    "    return reconstructed_cf[num_cols + ord_cols + l_enc_cols]"
   ],
   "id": "8524aaba30160270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.core.callback import Callback\n",
    "from pymoo.core.termination import Termination\n",
    "\n",
    "# warning occurs because the prediction is made without the column name, while it was trained with the column name\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")"
   ],
   "id": "1ee6ff70bf1847b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# helper function for the mutation\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.population import Population\n",
    "\n",
    "class DiverseBatchMutation(Mutation):\n",
    "    def __init__(self, actionable_idx, sem_functions,\n",
    "                 discrete_indices, xl, xu,  # <--- Essential: Receive bounds\n",
    "                 mutation_rate, rng):\n",
    "        super().__init__()\n",
    "        self.actionable_idx = actionable_idx\n",
    "        self.sem_functions = sem_functions\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.rng = rng\n",
    "\n",
    "        # Store bounds for use in _do()\n",
    "        self.discrete_indices = set(discrete_indices)\n",
    "        self.xl = xl\n",
    "        self.xu = xu\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        # Pass the STORED bounds, not the problem's bounds (safety)\n",
    "        X_mut = self.batch_mutate_diverse(\n",
    "            X,\n",
    "            actionable_idx=self.actionable_idx,\n",
    "            discrete_indices=self.discrete_indices,\n",
    "            xl=self.xl,\n",
    "            xu=self.xu,\n",
    "            mutation_rate=self.mutation_rate,\n",
    "            rng=self.rng\n",
    "        )\n",
    "\n",
    "        # Sanitize\n",
    "        X_mut = np.nan_to_num(X_mut, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        if self.xl is not None and self.xu is not None:\n",
    "             X_mut = np.clip(X_mut, self.xl, self.xu)\n",
    "\n",
    "        return X_mut\n",
    "\n",
    "    @staticmethod\n",
    "    def batch_mutate_diverse(X, actionable_idx, discrete_indices, xl, xu, mutation_rate, rng):\n",
    "        X = np.asarray(X)\n",
    "        is_1d = X.ndim == 1\n",
    "        X_mut = np.atleast_2d(X).copy()\n",
    "        n_samples, n_vars = X_mut.shape\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            for idx in actionable_idx:\n",
    "                if rng.random() < mutation_rate:\n",
    "\n",
    "                    # --- CATEGORICAL RESAMPLING ---\n",
    "                    if idx in discrete_indices:\n",
    "                        current_val = int(round(X_mut[i, idx]))\n",
    "\n",
    "                        # Use the Monotonic/Relaxed bounds we calculated in __init__\n",
    "                        min_val = int(xl[idx])\n",
    "                        max_val = int(xu[idx])\n",
    "\n",
    "                        # Generate candidates: integers in range [min, max] EXCLUDING current\n",
    "                        candidates = [v for v in range(min_val, max_val + 1) if v != current_val]\n",
    "\n",
    "                        if candidates:\n",
    "                            # Force a jump to a new category\n",
    "                            X_mut[i, idx] = rng.choice(candidates)\n",
    "\n",
    "                    # --- CONTINUOUS PERTURBATION ---\n",
    "                    else:\n",
    "                        # Standard Gaussian noise\n",
    "                        X_mut[i, idx] += rng.normal(0, 0.2)\n",
    "\n",
    "        if is_1d:\n",
    "            return X_mut[0]\n",
    "        return X_mut"
   ],
   "id": "d458ab637580047c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Counterfactual Generation\n",
    "class CounterfactualGeneration(Problem):\n",
    "    def __init__(self, model, original_data: pd.DataFrame, desired_class: int,\n",
    "                 actionable_features: list, immutable_features: list, feasible_preference_features: list,\n",
    "                 sem_functions: dict, causal_graph: nx.DiGraph, scaler,\n",
    "                 label_encoders, ord_cols, ord_orders, num_cols,\n",
    "                 l_enc_cols, feature_names, stochastic: bool = True,\n",
    "                 opt_cfg=None, seed=40, feature_utilities=None,\n",
    "                 tier_1_objectives=None, tier_2_objectives=None,\n",
    "                 lex_thresholds=None,):\n",
    "\n",
    "        self.opt_cfg = opt_cfg or {}\n",
    "        self.seed = seed\n",
    "        self.model = model\n",
    "        self.original_data = original_data.reset_index(drop=True)\n",
    "        self.desired_class = desired_class\n",
    "\n",
    "        # --- 1. SETUP FEATURES & INDICES ---\n",
    "        # We trust the column order of the original dataframe\n",
    "        self.features = list(original_data.columns)\n",
    "        self.actionable = [f for f in actionable_features if f in causal_graph.nodes]\n",
    "        self.immutable = [f for f in immutable_features if f in causal_graph.nodes]\n",
    "        self.feasible_preference_features = feasible_preference_features\n",
    "        # Map preferred features to their numerical index in the gene vector\n",
    "        self.mutable_indices = [\n",
    "            self.features.index(f) for f in feasible_preference_features if f in self.features\n",
    "        ]\n",
    "\n",
    "        # --- 2. CAUSAL & DECODER SETUP ---\n",
    "        self.sem_functions = sem_functions\n",
    "        self.graph = causal_graph\n",
    "        self.stochastic = stochastic\n",
    "        self.scaler = scaler\n",
    "        self.label_encoders = label_encoders\n",
    "        self.ord_cols = ord_cols\n",
    "        self.ord_orders = ord_orders\n",
    "        self.num_cols = num_cols\n",
    "        self.l_enc_cols = l_enc_cols\n",
    "        self.feature_names = feature_names\n",
    "        self.feature_utilities = feature_utilities or {}\n",
    "\n",
    "        self.tier_1_objectives = tier_1_objectives or [\"proximity\"]\n",
    "        self.tier_2_objectives = tier_2_objectives or [\"plausibility\", \"sparsity\", \"weighted_cost\"]\n",
    "        self.lex_thresholds = lex_thresholds or {\"validity\": 0, \"proximity\": 1.5}\n",
    "\n",
    "        # --- 3. QUANTIZATION SETUP ---\n",
    "        # Identify all columns that are NOT numerical (Ordinal + Categorical)\n",
    "        # We will force these to be integers during evaluation.\n",
    "        self.discrete_indices = []\n",
    "        for col in self.features:\n",
    "            if col not in self.num_cols:\n",
    "                self.discrete_indices.append(self.features.index(col))\n",
    "\n",
    "        # --- 4. PROBLEM DEFINITION ---\n",
    "        # 1. Define Standard Bounds (tight for continuous)\n",
    "        x_orig = original_data.iloc[0].values\n",
    "        eps = 0.5\n",
    "        xl = x_orig - eps\n",
    "        xu = x_orig + eps\n",
    "\n",
    "        # 2. RELAX BOUNDS for Categorical/Discrete Features (The Fix)\n",
    "        # We allow these features to span their full encoded range (e.g., 0 to n_classes-1)\n",
    "        for idx in self.discrete_indices:\n",
    "            feature_name = self.features[idx]\n",
    "\n",
    "            if idx in self.discrete_indices:\n",
    "                # Determine valid range based on encoder\n",
    "                if feature_name in self.label_encoders:\n",
    "                    # Nominal: 0 to len(classes) - 1\n",
    "                    lower = 0\n",
    "                    upper = len(self.label_encoders[feature_name].classes_) - 1\n",
    "                elif feature_name in self.ord_cols:\n",
    "                    # Ordinal: 0 to len(order) - 1\n",
    "                    # Find which ordinal order list corresponds to this col\n",
    "                    ord_idx = self.ord_cols.index(feature_name)\n",
    "                    lower = 0\n",
    "                    upper = len(self.ord_orders[ord_idx]) - 1\n",
    "                else:\n",
    "                    # Fallback\n",
    "                    lower, upper = xl[idx], xu[idx]\n",
    "\n",
    "                # Update bounds specifically for this feature\n",
    "                xl[idx] = lower\n",
    "                xu[idx] = upper\n",
    "\n",
    "        super().__init__(\n",
    "            n_var=len(self.features),\n",
    "            n_obj=4,\n",
    "            n_constr=2,\n",
    "            xl=xl,\n",
    "            xu=xu,\n",
    "        )\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        # ---------------------------------------------------------\n",
    "        # STEP 1: STRICT QUANTIZATION (The \"Snap-to-Grid\" Fix)\n",
    "        # ---------------------------------------------------------\n",
    "        # Force discrete genes to nearest integer.\n",
    "        # This ensures the Model sees exactly what the Decoder sees.\n",
    "        X_quantized = X.copy()\n",
    "        if len(self.discrete_indices) > 0:\n",
    "            X_quantized[:, self.discrete_indices] = np.round(X_quantized[:, self.discrete_indices])\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # STEP 2: REFERENCE DATA DECODING\n",
    "        # ---------------------------------------------------------\n",
    "        x_orig_encoded = self.original_data.iloc[0].values\n",
    "        orig_df_encoded = pd.DataFrame([x_orig_encoded], columns=self.features)\n",
    "\n",
    "        decoded_orig_df = decode_data(\n",
    "            valid_cfs=orig_df_encoded.values, scaler=self.scaler, label_encoders=self.label_encoders,\n",
    "            ord_cols=self.ord_cols, ord_orders=self.ord_orders, num_cols=self.num_cols,\n",
    "            l_enc_cols=self.l_enc_cols, feature_names=self.feature_names,\n",
    "        )\n",
    "        decoded_orig_row = decoded_orig_df.iloc[0]\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # STEP 3: CANDIDATE DECODING\n",
    "        # ---------------------------------------------------------\n",
    "        # Critical: Re-align columns to match what decode_data expects\n",
    "        X_quant_df = pd.DataFrame(X_quantized, columns=self.features)\n",
    "        X_quant_reordered = X_quant_df[self.feature_names].values\n",
    "\n",
    "        decoded_X = decode_data(\n",
    "            valid_cfs=X_quant_reordered, scaler=self.scaler, label_encoders=self.label_encoders,\n",
    "            ord_cols=self.ord_cols, ord_orders=self.ord_orders, num_cols=self.num_cols,\n",
    "            l_enc_cols=self.l_enc_cols, feature_names=self.feature_names,\n",
    "        )\n",
    "\n",
    "        F = []\n",
    "        pred_probs = []\n",
    "        # ---------------------------------------------------------\n",
    "        # STEP 4: EVALUATION LOOP\n",
    "        # ---------------------------------------------------------\n",
    "        for i, cf_vec in enumerate(X_quantized):\n",
    "\n",
    "            # A. Reconstruction (Apply gene changes to original data)\n",
    "            x_cf = self.original_data.iloc[0].copy()\n",
    "            for idx in self.mutable_indices:\n",
    "                x_cf.iloc[idx] = cf_vec[idx]\n",
    "\n",
    "            # B. Prediction (Using the STRICT QUANTIZED values)\n",
    "            x_input = x_cf.values.reshape(1, -1)\n",
    "            pred = self.model.predict(x_input)[0]\n",
    "            prob = self.model.predict_proba(x_input)[0, self.desired_class]\n",
    "            pred_probs.append(prob)\n",
    "\n",
    "            validity = 0 if pred == self.desired_class else 1\n",
    "\n",
    "            # C. Proximity\n",
    "            proximity = np.linalg.norm(x_cf.values - x_orig_encoded)\n",
    "\n",
    "            # D. Plausibility\n",
    "            plausibility = self.compute_plausibility(x_cf)\n",
    "\n",
    "            # E. Sparsity & Weighted Cost\n",
    "            x_cf_dec = decoded_X.iloc[i]\n",
    "            sparsity_count = 0.0\n",
    "            weighted_cost = 0.0\n",
    "\n",
    "            for idx in self.mutable_indices:\n",
    "                fname = self.features[idx]\n",
    "\n",
    "                # --- FIX START: Initialize the flag ---\n",
    "                changed = False\n",
    "                # --------------------------------------\n",
    "\n",
    "                # Determine Rank-Based Weight\n",
    "                if fname in self.feature_utilities:\n",
    "                    feature_weight = 1.0 + self.feature_utilities[fname].get(\"alpha\", 1.0)\n",
    "                else:\n",
    "                    feature_weight = 2.0\n",
    "\n",
    "                # Extract Values\n",
    "                val_cf = x_cf_dec[fname]\n",
    "                if hasattr(val_cf, 'item'): val_cf = val_cf.item()\n",
    "                val_orig = decoded_orig_row[fname]\n",
    "                if hasattr(val_orig, 'item'): val_orig = val_orig.item()\n",
    "\n",
    "                # Detect Change\n",
    "                if fname in self.num_cols:\n",
    "                    if not np.isclose(float(val_cf), float(val_orig), atol=1e-5):\n",
    "                        changed = True\n",
    "                else:\n",
    "                    if val_cf != val_orig:\n",
    "                        changed = True\n",
    "\n",
    "                # Accumulate Costs (Updated with Stagnation Penalty logic)\n",
    "                if changed:\n",
    "                    sparsity_count += 1.0\n",
    "                    weighted_cost += feature_weight\n",
    "\n",
    "                # Optional: Stagnation Penalty for Tier 1 (from previous suggestion)\n",
    "                elif fname in self.feature_utilities and self.feature_utilities[fname]['rank'] == 1:\n",
    "                     weighted_cost += 5.0 # Penalty for NOT changing a priority feature\n",
    "\n",
    "            # F. Constraints\n",
    "            tier1_violation = int(\n",
    "                (validity > self.lex_thresholds.get(\"validity\", 0)) or\n",
    "                (proximity > self.lex_thresholds.get(\"proximity\", 1.5))\n",
    "            )\n",
    "            penalty = 1e3 * tier1_violation\n",
    "\n",
    "            F.append([proximity + penalty, plausibility, sparsity_count, weighted_cost])\n",
    "\n",
    "        F = np.asarray(F)\n",
    "        pred_probs = np.asarray(pred_probs)\n",
    "\n",
    "        out[\"F\"] = F\n",
    "        out[\"G\"] = np.hstack([\n",
    "            np.maximum(0, 0.5 - pred_probs).reshape(-1, 1),\n",
    "            np.maximum(0, F[:, 0] - 6.0).reshape(-1, 1),\n",
    "        ])\n",
    "    def compute_plausibility(self, x_cf):\n",
    "        nll = 0.0\n",
    "        for node in nx.topological_sort(self.graph):\n",
    "            if node in self.actionable or node in self.immutable: continue\n",
    "            if node not in self.sem_functions: continue\n",
    "            parents = list(self.graph.predecessors(node))\n",
    "            if not parents: continue\n",
    "            parent_vals = x_cf[parents].values.reshape(1, -1)\n",
    "            if parent_vals.dtype == object: continue\n",
    "            sem_func, _ = self.sem_functions[node]\n",
    "            mu, sigma = sem_func(parent_vals)\n",
    "            mu = float(np.squeeze(mu))\n",
    "            sigma = float(np.squeeze(sigma)) + 1e-6\n",
    "            sampled = np.random.normal(mu, sigma) if self.stochastic else mu\n",
    "            nll += (sampled - mu) ** 2 / (2 * sigma ** 2)\n",
    "        return float(nll)\n"
   ],
   "id": "cad87ad3970b5d0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# optimization problem\n",
    "verified_feasible_features = tier1_features + tier2_features\n",
    "\n",
    "def build_cfe_problem(model, cf_data_instance, context,\n",
    "                      feasible_features, sem_functions,\n",
    "                      scaler, label_encoders, feature_names,\n",
    "                      desired_class=1, stochastic=True, opt_cfg=None,\n",
    "                      seed=45, feature_utilities=None, lex_thresholds=None,\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    Builds a lexicographic CounterfactualGeneration problem.\n",
    "    \"\"\"\n",
    "\n",
    "    opt_cfg = opt_cfg or BASELINE_OPT.copy()\n",
    "\n",
    "    problem = CounterfactualGeneration(\n",
    "        model=model,\n",
    "        original_data=cf_data_instance,\n",
    "        desired_class=desired_class,\n",
    "        actionable_features=context.actionable_features,\n",
    "        immutable_features=context.immutable_features,\n",
    "        feasible_preference_features=verified_feasible_features,\n",
    "        sem_functions=sem_functions,\n",
    "        causal_graph=context.causal_graph,\n",
    "        scaler=scaler,\n",
    "        label_encoders=label_encoders,\n",
    "        ord_cols=context.ord_cols,\n",
    "        ord_orders=context.ord_orders,\n",
    "        num_cols=context.num_cols,\n",
    "        l_enc_cols=context.l_enc_cols,\n",
    "        feature_names=feature_names,\n",
    "        stochastic=stochastic,\n",
    "        opt_cfg=opt_cfg,\n",
    "        seed=seed,\n",
    "        feature_utilities=feature_utilities,\n",
    "        lex_thresholds=lex_thresholds,\n",
    "    )\n",
    "\n",
    "    return problem\n",
    "\n",
    "def build_nsga3_algorithm(problem, opt_cfg, seed=40):\n",
    "    \"\"\"\n",
    "    Build NSGA-III algorithm using problem-aware configuration.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    ref_dirs = get_reference_directions(\n",
    "        \"das-dennis\",\n",
    "        n_dim=problem.n_obj,\n",
    "        n_partitions=opt_cfg.get(\"ref_partitions\", 4),\n",
    "    )\n",
    "\n",
    "    algorithm = NSGA3(\n",
    "        ref_dirs=ref_dirs,\n",
    "        pop_size=opt_cfg.get(\"pop_size\", len(ref_dirs)),\n",
    "        crossover=SBX(\n",
    "            prob=opt_cfg.get(\"crossover_prob\", 0.9),\n",
    "            eta=opt_cfg.get(\"mutation_eta\", 20),\n",
    "        ),\n",
    "        mutation=DiverseBatchMutation(\n",
    "            actionable_idx=problem.mutable_indices,\n",
    "            sem_functions=problem.sem_functions,\n",
    "\n",
    "            # --- INJECTING PROBLEM DATA HERE ---\n",
    "            discrete_indices=problem.discrete_indices,\n",
    "            xl=problem.xl,\n",
    "            xu=problem.xu,\n",
    "            # -----------------------------------\n",
    "\n",
    "            mutation_rate=opt_cfg.get(\"mutation_rate\", 0.4),\n",
    "            rng=rng,\n",
    "        ),\n",
    "        eliminate_duplicates=True,\n",
    "    )\n",
    "    return algorithm\n",
    "\n",
    "def generate_cfe(problem, algorithm=None, n_generations=100,\n",
    "                 n_seeds=5, N_valid=5,\n",
    "                 seed=40, verbose=True):\n",
    "    \"\"\"\n",
    "    Run lexicographic NSGA-III optimization and return diverse CF solutions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Boundary awareness\n",
    "    x_input = problem.original_data.values.reshape(1, -1)\n",
    "    proba = problem.model.predict_proba(x_input)[0][problem.desired_class]\n",
    "    log_odds = safe_log_odds(proba)\n",
    "\n",
    "    if abs(log_odds) > 0.2:\n",
    "        n_generations = int(n_generations * 1.5)\n",
    "\n",
    "    # Build algorithm if needed\n",
    "    if algorithm is None:\n",
    "        algorithm = build_nsga3_algorithm(\n",
    "            problem, opt_cfg=problem.opt_cfg, seed=seed\n",
    "        )\n",
    "\n",
    "    # --- FIX: Removed 'validity_index=0' to match your new class ---\n",
    "    # from pymoo.termination import get_termination\n",
    "    # termination = get_termination(\"n_gen\", n_generations)\n",
    "\n",
    "    termination = CounterfactualTermination(N=N_valid)\n",
    "\n",
    "    callback = LogCallback()\n",
    "\n",
    "    solutions = []\n",
    "\n",
    "    for s in range(n_seeds):\n",
    "        problem.seed = s\n",
    "        res = minimize(\n",
    "            problem,\n",
    "            algorithm,\n",
    "            termination=termination,\n",
    "            seed=s,\n",
    "            callback=callback,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        solutions.append(res.X)\n",
    "\n",
    "    return solutions\n",
    "\n",
    "\n",
    "# sensitivity analysis for the lexicographic ordering threshold\n",
    "def lexicographic_sensitivity_analysis(problem, algorithm, proximity_grid,\n",
    "                                       min_valid=5, seed=40, verbose=False,\n",
    "                                       ):\n",
    "    \"\"\"\n",
    "    Sensitivity analysis for Îµ-lexicographic proximity threshold.\n",
    "    \"\"\"\n",
    "    from pymoo.termination import get_termination\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for eps in proximity_grid:\n",
    "        problem.lex_thresholds[\"proximity\"] = eps\n",
    "\n",
    "        res = minimize(problem, algorithm,\n",
    "            termination=get_termination(\"n_gen\", 50),\n",
    "            seed=seed, verbose=verbose,\n",
    "                       )\n",
    "        F = res.F\n",
    "\n",
    "        # Valid solutions: no constraint violations\n",
    "        valid_mask = np.all(res.G <= 0, axis=1)\n",
    "\n",
    "        records.append({\n",
    "            \"eps\": eps,\n",
    "            \"n_valid\": valid_mask.sum(),\n",
    "            \"avg_plausibility\": np.mean(F[valid_mask, 1]) if valid_mask.any() else np.inf,\n",
    "            \"avg_sparsity\": np.mean(F[valid_mask, 2]) if valid_mask.any() else np.inf,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # Stability heuristic\n",
    "    stable_eps = df[\n",
    "        (df[\"n_valid\"] >= min_valid) &\n",
    "        (df[\"avg_plausibility\"].diff().abs() < 0.1)\n",
    "        ]\n",
    "\n",
    "    return df, stable_eps"
   ],
   "id": "f746e30fd93ab287",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ----------------------------\n",
    "# Logging callback\n",
    "# ----------------------------\n",
    "# tracks and visualize the search for optimal counterfactuals\n",
    "class LogCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data[\"gen\"] = []\n",
    "        self.data[\"n_evals\"] = []\n",
    "        self.data[\"opt\"] = []\n",
    "\n",
    "    def notify(self, algorithm):\n",
    "        self.data[\"gen\"].append(algorithm.n_gen)\n",
    "        self.data[\"n_evals\"].append(algorithm.evaluator.n_eval)\n",
    "        self.data[\"opt\"].append(algorithm.opt.get(\"F\"))\n",
    "\n",
    "# ----------------------------\n",
    "# Safe log odds\n",
    "# ----------------------------\n",
    "# transforms model outputs into a space where optimization is more effective or interpretable\n",
    "def safe_log_odds(prob):\n",
    "    eps = 1e-9\n",
    "    prob = np.clip(prob, eps, 1 - eps)\n",
    "    return np.log(prob / (1 - prob))\n",
    "\n",
    "# ----------------------------\n",
    "# Early Termination\n",
    "# ----------------------------\n",
    "class CounterfactualTermination(Termination):\n",
    "    def __init__(self, N=5):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "\n",
    "    def _update(self, algorithm):\n",
    "        # Get Constraint violations (G)\n",
    "        # G[:, 0] corresponds to the validity constraint defined in _evaluate\n",
    "        G = algorithm.opt.get(\"G\")\n",
    "\n",
    "        if G is None:\n",
    "            return False\n",
    "\n",
    "        # Count how many solutions satisfy the validity constraint (G <= 0)\n",
    "        valid_count = np.sum(G[:, 0] <= 0)\n",
    "\n",
    "        # Stop if we have found enough valid counterfactuals\n",
    "        return valid_count >= self.N"
   ],
   "id": "efbd8977c88a2452",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CFE reconstruction\n",
    "\n",
    "def reconstruct_counterfactuals(problem, X):\n",
    "    \"\"\"\n",
    "    Converts PyMOO decision vectors into full counterfactual records.\n",
    "\n",
    "    All features are preserved.\n",
    "    Only feasible user-preferred features are modified.\n",
    "    \"\"\"\n",
    "    x_orig = problem.original_data.iloc[0].copy()\n",
    "    cfs = []\n",
    "\n",
    "    for x in X:\n",
    "        x_cf = x_orig.copy()\n",
    "        # Apply ONLY to feasible preference features\n",
    "        for idx in problem.mutable_indices:\n",
    "            x_cf.iloc[idx] = x[idx]\n",
    "\n",
    "        cfs.append(x_cf)\n",
    "\n",
    "    return pd.DataFrame(cfs)\n",
    "\n",
    "def extract_valid_counterfactuals(problem, X_solutions, feasible_features):\n",
    "    # 1. Re-evaluate\n",
    "    out = {}\n",
    "    problem._evaluate(X_solutions, out)\n",
    "    F = out[\"F\"]\n",
    "    G = out[\"G\"]\n",
    "\n",
    "    # 2. Reconstruct (Returns ENCODED data in problem.features order)\n",
    "    cf_df_encoded = reconstruct_counterfactuals(problem, X_solutions)\n",
    "\n",
    "    # --- FIX 1: DECODE COUNTERFACTUALS WITH CORRECT COLUMN ORDER ---\n",
    "    # We must use problem.features (Encoded Order) so the data aligns with the names.\n",
    "    cf_df = decode_data(\n",
    "        valid_cfs=cf_df_encoded.values,\n",
    "        scaler=problem.scaler,\n",
    "        label_encoders=problem.label_encoders,\n",
    "        ord_cols=problem.ord_cols,\n",
    "        ord_orders=problem.ord_orders,\n",
    "        num_cols=problem.num_cols,\n",
    "        l_enc_cols=problem.l_enc_cols,\n",
    "        # CRITICAL FIX: Use Encoded Order\n",
    "        feature_names=problem.features\n",
    "    )\n",
    "\n",
    "    # 3. Define Names\n",
    "    objective_names = [\"proximity\", \"plausibility\", \"sparsity\", \"weighted_cost\"]\n",
    "    obj_df = pd.DataFrame(F, columns=objective_names)\n",
    "\n",
    "    # 4. Filter Validity\n",
    "    is_valid = G[:, 0] <= 0\n",
    "    cf_with_scores = pd.concat([cf_df.reset_index(drop=True), obj_df], axis=1)\n",
    "    cf_with_scores[\"is_valid\"] = is_valid\n",
    "    valid_cfs = cf_with_scores[cf_with_scores[\"is_valid\"] == True].copy()\n",
    "\n",
    "    # --- FIX 2: DECODE ORIGINAL DATA WITH CORRECT COLUMN ORDER ---\n",
    "    x_orig_encoded = problem.original_data.iloc[0].values.reshape(1, -1)\n",
    "    decoded_orig_df = decode_data(\n",
    "        valid_cfs=x_orig_encoded,\n",
    "        scaler=problem.scaler,\n",
    "        label_encoders=problem.label_encoders,\n",
    "        ord_cols=problem.ord_cols,\n",
    "        ord_orders=problem.ord_orders,\n",
    "        num_cols=problem.num_cols,\n",
    "        l_enc_cols=problem.l_enc_cols,\n",
    "        # CRITICAL FIX: Use Encoded Order\n",
    "        feature_names=problem.features\n",
    "    )\n",
    "    decoded_orig_row = decoded_orig_df.iloc[0]\n",
    "\n",
    "    # 5. PSR Calculation\n",
    "    def get_weighted_psr(row):\n",
    "        actual_score = 0.0\n",
    "        max_score = 0.0\n",
    "\n",
    "        full_wishlist = list(problem.feature_utilities.keys())\n",
    "        if not full_wishlist: return 100.0\n",
    "\n",
    "        num_prefs = len(full_wishlist)\n",
    "\n",
    "        # DEBUG HEADER\n",
    "        if row.name == 0:\n",
    "            print(f\"\\n--- PSR COMPARISON DEBUG ---\")\n",
    "\n",
    "        for fname in full_wishlist:\n",
    "            util = problem.feature_utilities[fname]\n",
    "            rank = util['rank']\n",
    "            weight = (num_prefs + 1) - rank\n",
    "            max_score += weight\n",
    "\n",
    "            orig_val = decoded_orig_row[fname]\n",
    "            cf_val = row[fname]\n",
    "\n",
    "            changed = False\n",
    "\n",
    "            # Robust Comparison\n",
    "            if fname in problem.num_cols:\n",
    "                 if not np.isclose(float(cf_val), float(orig_val), atol=1e-5):\n",
    "                     changed = True\n",
    "            else:\n",
    "                s_cf = str(cf_val).strip().lower()\n",
    "                s_orig = str(orig_val).strip().lower()\n",
    "                if s_cf != s_orig:\n",
    "                    changed = True\n",
    "                    if row.name == 0:\n",
    "                        print(f\"CHANGE: {fname} ('{s_orig}' -> '{s_cf}')\")\n",
    "\n",
    "            if changed:\n",
    "                actual_score += weight\n",
    "\n",
    "        if max_score == 0: return 0.0\n",
    "\n",
    "        if row.name == 0:\n",
    "            print(f\"Final PSR: {(actual_score/max_score)*100}%\")\n",
    "            print(\"----------------------------\\n\")\n",
    "\n",
    "        return (actual_score / max_score) * 100\n",
    "\n",
    "    if not valid_cfs.empty:\n",
    "        valid_cfs['psr_percent'] = valid_cfs.apply(get_weighted_psr, axis=1)\n",
    "\n",
    "    return valid_cfs.drop(columns=[\"is_valid\"])\n"
   ],
   "id": "cc8bbe470febd7a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Baseline (fixed)\n",
    "# -----------------------------\n",
    "BASELINE_OPT = dict(\n",
    "    pop_size=150,\n",
    "    n_generations=100,\n",
    "    mutation_eta=10,\n",
    "    crossover_prob=0.9,\n",
    "    ref_partitions=6\n",
    ")\n",
    "\n",
    "# data instance\n",
    "cf_data_instance = x_test_encoded[x_test_encoded['risk'] == 0].iloc[[20]].copy()\n",
    "cf_data_instance_t = cf_data_instance.drop(columns=['risk']).reset_index(drop=True)\n",
    "features_names = g_data.columns.tolist()\n"
   ],
   "id": "b81a00c78958148a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# STEP 1: INITIALIZE PROBLEM & ALGORITHM\n",
    "# ==============================================================================\n",
    "# This creates the objects required to run the sensitivity analysis.\n",
    "\n",
    "lex_thresholds = {\n",
    "    \"validity\": 0,     # must flip class\n",
    "    \"proximity\": 1.5   # initial Îµ (will be tuned later)\n",
    "}\n",
    "\n",
    "problem = build_cfe_problem(\n",
    "    model=svm_model,\n",
    "    cf_data_instance=cf_data_instance_t,\n",
    "    context=context,\n",
    "    feasible_features=feasible_features,\n",
    "    sem_functions=sem_functions,\n",
    "    scaler=scaler,\n",
    "    label_encoders=label_encoders,\n",
    "    feature_names=features_names,\n",
    "    desired_class=1,\n",
    "    stochastic=True,\n",
    "    opt_cfg=BASELINE_OPT,\n",
    "    feature_utilities=feature_utils,\n",
    "    lex_thresholds=lex_thresholds, # Starts with your default/wide thresholds\n",
    "    seed=45\n",
    ")\n",
    "\n",
    "algorithm = build_nsga3_algorithm(problem, opt_cfg=problem.opt_cfg, seed=45)\n",
    "\n",
    "solutions = generate_cfe(problem, algorithm=algorithm, n_generations=100,\n",
    "                         n_seeds=5, seed=45, verbose=True)\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 2: LEXICOGRAPHIC SENSITIVITY ANALYSIS\n",
    "# ==============================================================================\n",
    "# Now we use the objects defined above to find the \"Sweet Spot\"\n",
    "\n",
    "print(\"--- Starting Sensitivity Analysis ---\")\n",
    "proximity_grid = np.linspace(0.5, 5.0, 10)\n",
    "\n",
    "sensitivity_df, stable_eps = lexicographic_sensitivity_analysis(\n",
    "    problem=problem,     # Passes the problem you built in Step 1\n",
    "    algorithm=algorithm, # Passes the algorithm you built in Step 1\n",
    "    proximity_grid=proximity_grid,\n",
    "    min_valid=5,\n",
    "    seed=45,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Sensitivity Results:\")\n",
    "display(sensitivity_df)\n",
    "\n",
    "print(\"Stable Values\")\n",
    "display(stable_eps)\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 3: UPDATE PROBLEM WITH OPTIMAL THRESHOLD\n",
    "# ==============================================================================\n",
    "# We now modify the 'problem' object you created in Step 1 with the new value.\n",
    "\n",
    "if not stable_eps.empty:\n",
    "    optimal_epsilon = stable_eps.iloc[0]['eps']\n",
    "    print(f\"\\n>>> Selected Optimal Proximity Threshold (Îµ): {optimal_epsilon}\")\n",
    "else:\n",
    "    optimal_epsilon = 2.5 # Fallback\n",
    "    print(f\"\\n>>> Warning: No stable threshold found. Using fallback: {optimal_epsilon}\")\n",
    "\n",
    "# CRITICAL STEP: Update the existing problem instance\n",
    "problem.lex_thresholds[\"proximity\"] = optimal_epsilon\n",
    "\n",
    "# ==============================================================================\n",
    "# STEP 4: FINAL GENERATION\n",
    "# ==============================================================================\n",
    "# The 'problem' variable now contains the tuned threshold.\n",
    "\n",
    "print(f\"\\n--- Running Final Generation with Îµ={optimal_epsilon} ---\")\n",
    "\n",
    "# Run the final optimization\n",
    "res = minimize(problem, algorithm,\n",
    "               (\"n_gen\", 150), seed=45,\n",
    "               verbose=True)\n",
    "\n",
    "X_solutions = res.X\n",
    "valid_cfs = extract_valid_counterfactuals(problem, X_solutions, feasible_features)"
   ],
   "id": "e7b1ea6d2c24bf4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "valid_cfs",
   "id": "71b459a22d778d13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# List of objectives you defined\n",
    "# objective_names = [\"validity\", \"proximity\", \"plausibility\", \"sparsity\", \"psr\"]\n",
    "\n",
    "objective_names = [\"proximity\", \"plausibility\", \"sparsity\", \"psr_percent\", \"weighted_cost\"]\n",
    "# Extract only the objective columns\n",
    "objectives_df = valid_cfs[objective_names]\n",
    "objectives_df\n"
   ],
   "id": "dbfa317255dc8db9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cf_data_instance",
   "id": "f8b2b4e03cfcfd34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_instance",
   "id": "230b97a979f73f91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compare_instance_with_cfes(data_instance: pd.DataFrame, decoded_cfes: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Compare a single original instance with multiple decoded counterfactuals.\n",
    "    Highlights changes with \"old â†’ new\" notation.\n",
    "\n",
    "    Args:\n",
    "        data_instance: pd.DataFrame with a single row (original instance, human-readable)\n",
    "        decoded_cfes: pd.DataFrame of counterfactuals (human-readable)\n",
    "\n",
    "    Returns:\n",
    "        pd.io.formats.style.Styler: styled DataFrame showing changes\n",
    "    \"\"\"\n",
    "\n",
    "    # Function to highlight changes\n",
    "    def highlight_changes(val):\n",
    "        if isinstance(val, str) and \"â†’\" in val:\n",
    "            return \"background-color: #d4edda; color: green; font-weight: bold;\"  # light green\n",
    "        return \"\"\n",
    "\n",
    "    # Repeat the original instance to match CF rows\n",
    "    original_repeated = pd.concat([data_instance]*decoded_cfes.shape[0], ignore_index=True)\n",
    "\n",
    "    # Convert both to strings for comparison\n",
    "    original_str = original_repeated.astype(str)\n",
    "    cf_str = decoded_cfes.astype(str)\n",
    "\n",
    "    # Align columns in case of any mismatch\n",
    "    original_str, cf_str = original_str.align(cf_str, join='inner', axis=1)\n",
    "\n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = original_str.copy()\n",
    "\n",
    "    for col in comparison_df.columns:\n",
    "        diff_mask = original_str[col] != cf_str[col]\n",
    "        comparison_df.loc[diff_mask, col] = original_str.loc[diff_mask, col] + \" â†’ \" + cf_str.loc[diff_mask, col]\n",
    "\n",
    "    # Use Styler.map instead of deprecated applymap\n",
    "    styled_df = comparison_df.style.map(highlight_changes)\n",
    "    return styled_df\n"
   ],
   "id": "15f1ccb5aafd5e4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# original_decoded: single-row original instance\n",
    "# decoded_cf_df: reconstructed human-readable CFEs\n",
    "styled_comparison = compare_instance_with_cfes(data_instance, valid_cfs)\n",
    "styled_comparison\n"
   ],
   "id": "c0898a81b9d707ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "user_preferences",
   "id": "dcb7bd538fb7f0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "feasible_features",
   "id": "b0bcc41bb40ab234",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
